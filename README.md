# DigitalHuman25 — Team 9: Project Repository

Welcome to the DigitalHuman25, Team 9 repository! This space hosts all the necessary code and resources to reproduce our project's results.

### Image Data

Before you begin, please download the required image dataset and save them in my_cat directory

[**Download Image Data Here**](https://drive.google.com/drive/folders/1kZ65uW2QijOylpZ5MaN_HKFF6E_PR64a)

### Project Structure

For seamless execution, ensure your project directory is organized as follows:
```bash
.
├── train_dreambooth.py
├── animatediff.py
├── calculate_xxx.py
├── inference_xxx.py
├── ppl_cat
├── my_cat/
│   ├── baseline
│   ├── less_camera_distribute
│   ├── less_img
│   ├── more_camera_distribute
│   └── more_img
```
This structure ensures all scripts can correctly locate necessary files.

### Reproducing Our Results

To get started, **adjust the file paths within the scripts** to align with your specific working directory. Once configured, follow these steps:

* **Create your environment and install the required packages:**
    ```bash
    pip install -r requirements.txt
    ```
* **Then initialize an Accelerate environment :**
    ```bash
    accelerate config
    ```
* **Fine-Tune the Diffusion Model:**
    
    We use the script provided by huggingface diffusers to fine-tune the model and save it to your output directory (INSTANCE_DIR has 5 different options):
    ```bash
    export MODEL_NAME="CompVis/stable-diffusion-v1-4"
    export INSTANCE_DIR="my_cat/baseline"
    export OUTPUT_DIR="path-to-save-model"

    accelerate launch train_dreambooth.py \
    --pretrained_model_name_or_path=$MODEL_NAME  \
    --instance_data_dir=$INSTANCE_DIR \
    --output_dir=$OUTPUT_DIR \
    --instance_prompt="a photo of sks cat" \
    --resolution=512 \
    --train_batch_size=1 \
    --gradient_accumulation_steps=1 \
    --learning_rate=5e-6 \
    --lr_scheduler="constant" \
    --lr_warmup_steps=0 \
    --max_train_steps=400
    ```
    Moreover, if you want to add a prior preservation loss during training, run:
    ```bash
    export MODEL_NAME="CompVis/stable-diffusion-v1-4"
    export INSTANCE_DIR="my_cat/baseline"
    export CLASS_DIR="ppl_cat"
    export OUTPUT_DIR="path-to-save-model"

    accelerate launch train_dreambooth.py \
    --pretrained_model_name_or_path=$MODEL_NAME  \
    --instance_data_dir=$INSTANCE_DIR \
    --class_data_dir=$CLASS_DIR \
    --output_dir=$OUTPUT_DIR \
    --with_prior_preservation --prior_loss_weight=1.0 \
    --instance_prompt="a photo of sks cat" \
    --class_prompt="a photo of cat" \
    --resolution=512 \
    --train_batch_size=1 \
    --gradient_accumulation_steps=1 \
    --learning_rate=5e-6 \
    --lr_scheduler="constant" \
    --lr_warmup_steps=0 \
    --num_class_images=200 \
    --max_train_steps=800
    ```
    The directory `ppl_cat` contains 200 images of random cats generated by the pretrained model. You can download them from the google drive, or you can generate them for yourself if you want.

* **Generate Image Samples:**
    To create new image samples, first **edit the `prompt_list` within `inference.py`** to define your desired outputs. Then modify the path of your model and run:
    ```bash
    python inference.py
    ```
    The generated images will be saved at folder `./sks_cat`
* **Generate Video Samples:**
    Similarly, for video generation, **modify the `prompt_list` in `animatediff.py`** with your chosen prompts. Modify the path of your model and execute the script:
    ```bash
    python animatediff.py
    ```
    The generated gifs will be saved at folder `./sks_cat_animation`
* **Calculate Performance Metrics:**
  
    To calculate PRES metrics, you need to first generate images of random cats with the fine-tuned model. You may run:
    ```bash
    python inference_pres.py
    ```
    The generated images will be saved at folder `./pres_cat`

    To evaluate the performance of our models, modify the `method` or `img_folder` in calculate_xxx.py, and then run the following command:
    ```bash
    python calculate_xxx.py
    ```
